{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b2769d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data...\n",
      "Load Data...\n",
      "dimensionality reduction...\n",
      "[331701.75834761 245814.59286268 212059.79058611 185630.82147794\n",
      " 167042.84107444 147541.29635202 112176.96232634 100010.99546987\n",
      "  94748.48356174  80587.3855047   72105.84020915  70513.0919171\n",
      "  58763.80498815  57964.52245562  54372.44762443  50909.8343758\n",
      "  45394.12771989  44348.66953099  40951.71810408  39639.71407389\n",
      "  36795.71459726  34589.30233391  33050.73981938  31274.69263663\n",
      "  30729.59354755  28597.95197996  27953.90468762  27043.25132216\n",
      "  25441.66573241  23705.67939694  22630.70163851  21873.50815989\n",
      "  20739.7358665   20236.43377375  19413.41986056  18433.76984404\n",
      "  17363.60086878  16852.00451097  16360.39678777  16097.37092188\n",
      "  15638.92379312  15296.04013005  14382.04943549  13704.77823719\n",
      "  13260.02266353  12943.71370253  12386.16548159  12012.8368315\n",
      "  11572.13357476  11086.17527631  10733.1994477   10621.54821293] \n",
      " [0.09661074 0.07159543 0.06176408 0.05406644 0.04865254 0.04297256\n",
      " 0.03267242 0.02912899 0.02759624 0.02347171 0.02100139 0.02053749\n",
      " 0.01711542 0.01688262 0.0158364  0.01482789 0.0132214  0.0129169\n",
      " 0.01192751 0.01154538 0.01071704 0.01007441 0.00962629 0.009109\n",
      " 0.00895024 0.00832938 0.00814179 0.00787656 0.00741009 0.00690447\n",
      " 0.00659137 0.00637083 0.00604061 0.00589402 0.00565431 0.00536898\n",
      " 0.00505729 0.00490828 0.00476509 0.00468849 0.00455496 0.00445509\n",
      " 0.00418888 0.00399162 0.00386209 0.00376996 0.00360757 0.00349883\n",
      " 0.00337047 0.00322894 0.00312613 0.00309361] \n",
      " 52\n",
      "0.8315702401616137\n",
      "Train SVM...\n",
      "Model train time used:30.802687 s\n",
      "i=52 3700 62.0 0.016756756756756756\n",
      "i=52 >>>>> \t 3700 62 0.9832432432432432\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       384\n",
      "           1       0.99      1.00      0.99       409\n",
      "           2       0.98      0.98      0.98       375\n",
      "           3       0.99      0.96      0.98       370\n",
      "           4       0.98      0.98      0.98       356\n",
      "           5       0.97      0.99      0.98       337\n",
      "           6       0.99      0.99      0.99       373\n",
      "           7       0.98      0.98      0.98       400\n",
      "           8       0.97      0.98      0.98       327\n",
      "           9       0.99      0.97      0.98       369\n",
      "\n",
      "    accuracy                           0.98      3700\n",
      "   macro avg       0.98      0.98      0.98      3700\n",
      "weighted avg       0.98      0.98      0.98      3700\n",
      "\n",
      "特征数量= 52, 存在最优解：>>> \t 3700 62 0.9832432432432432\n",
      "finish!\n",
      "TrainModel store time used:43.115376 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d0d24986969c>:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  cov_all_score = float(sum(eigvals))\n",
      "<ipython-input-1-d0d24986969c>:102: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  line_cov_score = float(eigvals[eigValInd[i]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主成分： 1, 方差占比：9.68%, 累积方差占比： 9.7%\n",
      "主成分： 2, 方差占比：7.16%, 累积方差占比：16.8%\n",
      "主成分： 3, 方差占比：6.17%, 累积方差占比：23.0%\n",
      "主成分： 4, 方差占比：5.38%, 累积方差占比：28.4%\n",
      "主成分： 5, 方差占比：4.87%, 累积方差占比：33.3%\n",
      "主成分： 6, 方差占比：4.30%, 累积方差占比：37.6%\n",
      "主成分： 7, 方差占比：3.28%, 累积方差占比：40.8%\n",
      "主成分： 8, 方差占比：2.90%, 累积方差占比：43.7%\n",
      "主成分： 9, 方差占比：2.77%, 累积方差占比：46.5%\n",
      "主成分：10, 方差占比：2.35%, 累积方差占比：48.8%\n",
      "主成分：11, 方差占比：2.10%, 累积方差占比：51.0%\n",
      "主成分：12, 方差占比：2.06%, 累积方差占比：53.0%\n",
      "主成分：13, 方差占比：1.71%, 累积方差占比：54.7%\n",
      "主成分：14, 方差占比：1.69%, 累积方差占比：56.4%\n",
      "主成分：15, 方差占比：1.58%, 累积方差占比：58.0%\n",
      "主成分：16, 方差占比：1.49%, 累积方差占比：59.5%\n",
      "主成分：17, 方差占比：1.32%, 累积方差占比：60.8%\n",
      "主成分：18, 方差占比：1.29%, 累积方差占比：62.1%\n",
      "主成分：19, 方差占比：1.19%, 累积方差占比：63.3%\n",
      "主成分：20, 方差占比：1.16%, 累积方差占比：64.4%\n",
      "主成分：21, 方差占比：1.07%, 累积方差占比：65.5%\n",
      "主成分：22, 方差占比：1.01%, 累积方差占比：66.5%\n",
      "主成分：23, 方差占比：0.96%, 累积方差占比：67.5%\n",
      "主成分：24, 方差占比：0.91%, 累积方差占比：68.4%\n",
      "主成分：25, 方差占比：0.89%, 累积方差占比：69.3%\n",
      "主成分：26, 方差占比：0.84%, 累积方差占比：70.1%\n",
      "主成分：27, 方差占比：0.81%, 累积方差占比：70.9%\n",
      "主成分：28, 方差占比：0.78%, 累积方差占比：71.7%\n",
      "主成分：29, 方差占比：0.74%, 累积方差占比：72.5%\n",
      "主成分：30, 方差占比：0.69%, 累积方差占比：73.2%\n",
      "主成分：31, 方差占比：0.66%, 累积方差占比：73.8%\n",
      "主成分：32, 方差占比：0.64%, 累积方差占比：74.5%\n",
      "主成分：33, 方差占比：0.60%, 累积方差占比：75.1%\n",
      "主成分：34, 方差占比：0.59%, 累积方差占比：75.6%\n",
      "主成分：35, 方差占比：0.57%, 累积方差占比：76.2%\n",
      "主成分：36, 方差占比：0.54%, 累积方差占比：76.7%\n",
      "主成分：37, 方差占比：0.51%, 累积方差占比：77.3%\n",
      "主成分：38, 方差占比：0.49%, 累积方差占比：77.7%\n",
      "主成分：39, 方差占比：0.48%, 累积方差占比：78.2%\n",
      "主成分：40, 方差占比：0.47%, 累积方差占比：78.7%\n",
      "主成分：41, 方差占比：0.46%, 累积方差占比：79.1%\n",
      "主成分：42, 方差占比：0.44%, 累积方差占比：79.6%\n",
      "主成分：43, 方差占比：0.42%, 累积方差占比：80.0%\n",
      "主成分：44, 方差占比：0.40%, 累积方差占比：80.4%\n",
      "主成分：45, 方差占比：0.39%, 累积方差占比：80.8%\n",
      "主成分：46, 方差占比：0.38%, 累积方差占比：81.2%\n",
      "主成分：47, 方差占比：0.36%, 累积方差占比：81.5%\n",
      "主成分：48, 方差占比：0.35%, 累积方差占比：81.9%\n",
      "主成分：49, 方差占比：0.34%, 累积方差占比：82.2%\n",
      "主成分：50, 方差占比：0.32%, 累积方差占比：82.5%\n",
      "主成分：51, 方差占比：0.32%, 累积方差占比：82.9%\n",
      "主成分：52, 方差占比：0.31%, 累积方差占比：83.2%\n",
      "主成分：53, 方差占比：0.29%, 累积方差占比：83.5%\n",
      "主成分：54, 方差占比：0.29%, 累积方差占比：83.7%\n",
      "主成分：55, 方差占比：0.28%, 累积方差占比：84.0%\n",
      "主成分：56, 方差占比：0.27%, 累积方差占比：84.3%\n",
      "主成分：57, 方差占比：0.27%, 累积方差占比：84.6%\n",
      "主成分：58, 方差占比：0.26%, 累积方差占比：84.8%\n",
      "主成分：59, 方差占比：0.25%, 累积方差占比：85.1%\n",
      "主成分：60, 方差占比：0.25%, 累积方差占比：85.3%\n",
      "主成分：61, 方差占比：0.24%, 累积方差占比：85.6%\n",
      "主成分：62, 方差占比：0.24%, 累积方差占比：85.8%\n",
      "主成分：63, 方差占比：0.23%, 累积方差占比：86.0%\n",
      "主成分：64, 方差占比：0.22%, 累积方差占比：86.2%\n",
      "主成分：65, 方差占比：0.21%, 累积方差占比：86.5%\n",
      "主成分：66, 方差占比：0.21%, 累积方差占比：86.7%\n",
      "主成分：67, 方差占比：0.20%, 累积方差占比：86.9%\n",
      "主成分：68, 方差占比：0.20%, 累积方差占比：87.1%\n",
      "主成分：69, 方差占比：0.19%, 累积方差占比：87.3%\n",
      "主成分：70, 方差占比：0.19%, 累积方差占比：87.4%\n",
      "主成分：71, 方差占比：0.19%, 累积方差占比：87.6%\n",
      "主成分：72, 方差占比：0.18%, 累积方差占比：87.8%\n",
      "主成分：73, 方差占比：0.18%, 累积方差占比：88.0%\n",
      "主成分：74, 方差占比：0.17%, 累积方差占比：88.2%\n",
      "主成分：75, 方差占比：0.17%, 累积方差占比：88.3%\n",
      "主成分：76, 方差占比：0.16%, 累积方差占比：88.5%\n",
      "主成分：77, 方差占比：0.16%, 累积方差占比：88.7%\n",
      "主成分：78, 方差占比：0.15%, 累积方差占比：88.8%\n",
      "主成分：79, 方差占比：0.15%, 累积方差占比：89.0%\n",
      "主成分：80, 方差占比：0.14%, 累积方差占比：89.1%\n",
      "主成分：81, 方差占比：0.14%, 累积方差占比：89.2%\n",
      "主成分：82, 方差占比：0.14%, 累积方差占比：89.4%\n",
      "主成分：83, 方差占比：0.14%, 累积方差占比：89.5%\n",
      "主成分：84, 方差占比：0.14%, 累积方差占比：89.7%\n",
      "主成分：85, 方差占比：0.13%, 累积方差占比：89.8%\n",
      "主成分：86, 方差占比：0.13%, 累积方差占比：89.9%\n",
      "主成分：87, 方差占比：0.13%, 累积方差占比：90.1%\n",
      "主成分：88, 方差占比：0.12%, 累积方差占比：90.2%\n",
      "主成分：89, 方差占比：0.12%, 累积方差占比：90.3%\n",
      "主成分：90, 方差占比：0.12%, 累积方差占比：90.4%\n",
      "主成分：91, 方差占比：0.12%, 累积方差占比：90.5%\n",
      "主成分：92, 方差占比：0.11%, 累积方差占比：90.7%\n",
      "主成分：93, 方差占比：0.11%, 累积方差占比：90.8%\n",
      "主成分：94, 方差占比：0.11%, 累积方差占比：90.9%\n",
      "主成分：95, 方差占比：0.11%, 累积方差占比：91.0%\n",
      "主成分：96, 方差占比：0.11%, 累积方差占比：91.1%\n",
      "主成分：97, 方差占比：0.10%, 累积方差占比：91.2%\n",
      "主成分：98, 方差占比：0.10%, 累积方差占比：91.3%\n",
      "主成分：99, 方差占比：0.10%, 累积方差占比：91.4%\n",
      "主成分：100, 方差占比：0.10%, 累积方差占比：91.5%\n",
      "Model pre time used:8.066257 s\n",
      "Saved successfully...\n",
      "finish!\n",
      "PreModel load time used:8.081879 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 数据路径\n",
    "data_dir = 'D:\\jupyter/digit-recognizer/'\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "def opencsv():\n",
    "    print('Load Data...')\n",
    "    # 使用 pandas 打开\n",
    "    dataTrain = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    dataPre = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    trainData = dataTrain.values[:, 1:]  # 读入全部训练数据\n",
    "    trainLabel = dataTrain.values[:, 0]\n",
    "    preData = dataPre.values[:, 1:]  # 测试全部测试个数据\n",
    "    return trainData, trainLabel, preData\n",
    "\n",
    "\n",
    "# 数据预处理-降维 PCA主成成分分析\n",
    "def dRCsv(x_train, x_test, preData, COMPONENT_NUM):\n",
    "    print('dimensionality reduction...')\n",
    "    trainData = np.array(x_train)\n",
    "    testData = np.array(x_test)\n",
    "    preData = np.array(preData)\n",
    "\n",
    "    '''\n",
    "    使用说明：https://www.cnblogs.com/pinard/p/6243025.html\n",
    "    n_components>=1\n",
    "      n_components=NUM  \b 设置\b占特征数量比\n",
    "    0 < n_components < 1\n",
    "      n_components=0.99  \b设置阈值总方差占比\n",
    "    '''\n",
    "    pca = PCA(n_components=COMPONENT_NUM, whiten=True)\n",
    "    pca.fit(trainData)  # Fit the model with X\n",
    "    pcaTrainData = pca.transform(trainData)  # Fit the model with X and 在X上完成降维.\n",
    "    pcaTestData = pca.transform(testData)  # Fit the model with X and 在X上完成降维.\n",
    "    pcaPreData = pca.transform(preData)  # Fit the model with X and 在X上完成降维.\n",
    "\n",
    "    # pca 方差大小、方差占比、特征数量\n",
    "    print(pca.explained_variance_, '\\n', pca.explained_variance_ratio_, '\\n', pca.n_components_)\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    return pcaTrainData,  pcaTestData, pcaPreData\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def trainModel(trainData, trainLabel):\n",
    "    print('Train SVM...')\n",
    "    clf = SVC(C=4, kernel='rbf')\n",
    "    clf.fit(trainData, trainLabel)  # 训练SVM\n",
    "    return clf\n",
    "\n",
    "\n",
    "# 结果输出保存\n",
    "def saveResult(result, csvName):\n",
    "    with open(csvName, 'w') as myFile:\n",
    "        myWriter = csv.writer(myFile)\n",
    "        myWriter.writerow([\"ImageId\", \"Label\"])\n",
    "        index = 0\n",
    "        for r in result:\n",
    "            index += 1\n",
    "            myWriter.writerow([index, int(r)])\n",
    "    print('Saved successfully...')  # 保存预测结果\n",
    "\n",
    "\n",
    "# 分析数据,看数据是否满足要求（通过这些来检测数据的相关性，考虑在分类的时候提取出重要的特征）\n",
    "def analyse_data(dataMat):\n",
    "    meanVals = np.mean(dataMat, axis=0)  # np.mean 求出每列的平均值meanVals\n",
    "    meanRemoved = dataMat-meanVals  # 每一列特征值减去该列的特征值均值\n",
    "    # 计算协方差矩阵，除数n-1是为了得到协方差的 无偏估计\n",
    "    # cov(X,0) = cov(X) 除数是n-1(n为样本个数)\n",
    "    # cov(X,1) 除数是n\n",
    "    covMat = np.cov(meanRemoved, rowvar=0)  # cov 计算协方差的值,\n",
    "    # np.mat 是用来生成一个矩阵的\n",
    "    # 保存特征值(eigvals)和对应的特征向量(eigVects)\n",
    "    eigvals, eigVects = np.linalg.eig(np.mat(covMat))  # linalg.eig 计算的值是矩阵的特征值，保存在对应的矩阵中\n",
    "    eigValInd = np.argsort(eigvals)  # argsort 对特征值进行排序，返回的是数值从小到大的索引值\n",
    "\n",
    "    topNfeat = 100  # 需要保留的特征维度，即要压缩成的维度数\n",
    "\n",
    "    # 从排序后的矩阵最后一个开始自下而上选取最大的N个特征值，返回其对应的索引\n",
    "    eigValInd = eigValInd[:-(topNfeat+1):-1]\n",
    "\n",
    "    # 计算特征值的总和\n",
    "    cov_all_score = float(sum(eigvals))\n",
    "    sum_cov_score = 0\n",
    "    for i in range(0, len(eigValInd)):\n",
    "        # 特征值进行相加\n",
    "        line_cov_score = float(eigvals[eigValInd[i]])\n",
    "        sum_cov_score += line_cov_score\n",
    "        '''\n",
    "        我们发现其中有超过20%的特征值都是0。\n",
    "        这就意味着这些特征都是其他特征的副本，也就是说，它们可以通过其他特征来表示，而本身并没有提供额外的信息。\n",
    "\n",
    "        最前面15个值的数量级大于10^5，实际上那以后的值都变得非常小。\n",
    "        这就相当于告诉我们只有部分重要特征，重要特征的数目也很快就会下降。\n",
    "\n",
    "        最后，我们可能会注意到有一些小的负值，他们主要源自数值误差应该四舍五入成0.\n",
    "        '''\n",
    "        print('主成分：%s, 方差占比：%s%%, 累积方差占比：%s%%' % (format(i+1, '2.0f'), format(line_cov_score/cov_all_score*100, '4.2f'), format(sum_cov_score/cov_all_score*100, '4.1f')))\n",
    "\n",
    "\n",
    "# 找出最高准确率\n",
    "def getOptimalAccuracy(trainData, trainLabel, preData):\n",
    "    # 分析数据 100个特征左右\n",
    "    # analyse_data(trainData)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(trainData, trainLabel, test_size=0.1)\n",
    "    lineLen, featureLen = np.shape(x_test) # shape 返回矩阵或者数值的长度\n",
    "    # print(lineLen, type(lineLen), featureLen, type(featureLen))\n",
    "\n",
    "    minErr = 1\n",
    "    minSumErr = 0\n",
    "    optimalNum = 1\n",
    "    optimalLabel = []\n",
    "    optimalSVMClf = None\n",
    "    pcaPreDataResult = None\n",
    "    for i in range(52,53, 1):\n",
    "        # 评估训练结果\n",
    "        pcaTrainData,  pcaTestData, pcaPreData = dRCsv(x_train, x_test, preData, i)\n",
    "        \n",
    "        train_start = time.time() #记录训练开始时间\n",
    "        clf = trainModel(pcaTrainData, y_train)#clf = trainModel(pcaTrainData, y_train)\n",
    "        train_end = time.time()#记录训练结束时间\n",
    "        print('Model train time used:%f s' % (train_end - train_start))\n",
    "        \n",
    "        testLabel = clf.predict(pcaTestData)#使用模型预测验证集的标签 testLabel = clf.predict(pcaTestData)\n",
    "\n",
    "        errArr = np.mat(np.ones((lineLen, 1)))\n",
    "        sumErrArr = errArr[testLabel != y_test].sum()\n",
    "        sumErr = sumErrArr/lineLen\n",
    "\n",
    "        print('i=%s' % i, lineLen, sumErrArr, sumErr)\n",
    "        if sumErr <= minErr:\n",
    "            minErr = sumErr\n",
    "            minSumErr = sumErrArr\n",
    "            optimalNum = i\n",
    "            optimalSVMClf = clf\n",
    "            optimalLabel = testLabel\n",
    "            pcaPreDataResult = pcaPreData\n",
    "            print(\"i=%s >>>>> \\t\" % i, lineLen, int(minSumErr), 1-minErr)\n",
    "\n",
    "    '''\n",
    "    展现 准确率与召回率\n",
    "        precision 准确率\n",
    "        recall 召回率\n",
    "        f1-score  准确率和召回率的一个综合得分\n",
    "        support 参与比较的数量\n",
    "    # target_names 以 y的label分类为准\n",
    "    # target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    target_names = [str(i) for i in list(set(y_test))]\n",
    "    print(target_names)\n",
    "    print(classification_report(y_test, optimalLabel, target_names=target_names))\n",
    "    print(\"特征数量= %s, 存在最优解：>>> \\t\" % optimalNum, lineLen, int(minSumErr), 1-minErr)\n",
    "    return optimalSVMClf, pcaPreDataResult\n",
    "\n",
    "\n",
    "# 存储模型\n",
    "def storeModel(model, filename):\n",
    "    import pickle\n",
    "    with open(filename, 'wb') as fw:\n",
    "        pickle.dump(model, fw)\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "def getModel(filename):\n",
    "    import pickle\n",
    "    fr = open(filename, 'rb')\n",
    "    return pickle.load(fr)\n",
    "\n",
    "\n",
    "def trainDRSVM():\n",
    "    startTime = time.time()\n",
    "\n",
    "    # 加载数据\n",
    "    trainData, trainLabel, preData = opencsv()\n",
    "    # 模型训练 (数据预处理-降维)\n",
    "    optimalSVMClf, pcaPreData = getOptimalAccuracy(trainData, trainLabel, preData)\n",
    "\n",
    "    storeModel(optimalSVMClf, os.path.join(data_dir, 'Result_sklearn_SVM.model'))\n",
    "    storeModel(pcaPreData, os.path.join(data_dir, 'Result_sklearn_SVM.pcaPreData'))\n",
    "\n",
    "    print(\"finish!\")\n",
    "    stopTime = time.time()\n",
    "    print('TrainModel store time used:%f s' % (stopTime - startTime))\n",
    "\n",
    "\n",
    "def preDRSVM():\n",
    "    startTime = time.time()\n",
    "    # 加载模型和数据\n",
    "    optimalSVMClf = getModel(os.path.join(data_dir, 'Result_sklearn_SVM.model'))\n",
    "    pcaPreData = getModel(os.path.join(data_dir, 'Result_sklearn_SVM.pcaPreData'))\n",
    "\n",
    "    # 结果预测\n",
    "    train_start = time.time() #记录训练开始时间\n",
    "    testLabel = optimalSVMClf.predict(pcaPreData)\n",
    "    train_end = time.time()#记录训练结束时间\n",
    "    print('Model pre time used:%f s' % (train_end - train_start))\n",
    "    # print(\"testLabel = %f\" % testscore)\n",
    "    # 结果的输出\n",
    "    saveResult(testLabel, os.path.join(data_dir, 'Result_sklearn_SVM.csv'))\n",
    "    print(\"finish!\")\n",
    "    stopTime = time.time()\n",
    "    print('PreModel load time used:%f s' % (stopTime - startTime))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainData, trainLabel, preData = opencsv()\n",
    "\n",
    "    # 训练并保存模型\n",
    "    trainDRSVM()\n",
    "\n",
    "    # 分析数据\n",
    "    analyse_data(trainData)\n",
    "    # 加载预测数据集\n",
    "    preDRSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93877aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
